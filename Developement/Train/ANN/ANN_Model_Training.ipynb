{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "qV7YcgWQXHGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8abb5fce-cc2c-45fb-ca96-114583397773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti6J5_p2U-hK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "htru2 = fetch_ucirepo(id=372)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = htru2.data.features\n",
        "y = htru2.data.targets\n",
        "\n",
        "y = y.values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT9g-Eka24vX",
        "outputId": "e9b62722-5862-4d23-a77a-ce4e2bc4f83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5370, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "# SMOTEENN\n",
        "smoteenn = SMOTEENN(random_state=42)\n",
        "X_resampled, y_resampled = smoteenn.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "967g_QJjXVlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle outliers using IQR\n",
        "# def remove_outliers_iqr(X, y):\n",
        "#     Q1 = np.percentile(X, 25, axis=0)\n",
        "#     Q3 = np.percentile(X, 75, axis=0)\n",
        "#     IQR = Q3 - Q1\n",
        "#     lower_bound = Q1 - 1.5 * IQR\n",
        "#     upper_bound = Q3 + 1.5 * IQR\n",
        "#     mask = np.all((X >= lower_bound) & (X <= upper_bound), axis=1)\n",
        "#     return X[mask], y[mask]\n",
        "\n",
        "# X_resampled, y_resampled = remove_outliers_iqr(X_resampled, y_resampled)\n"
      ],
      "metadata": {
        "id": "zLCE5F1xXXTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "train_dataset = TensorDataset(torch.tensor(X_resampled, dtype=torch.float32), torch.tensor(y_resampled, dtype=torch.float32).view(-1, 1))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).view(-1, 1))\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the ANN model\n",
        "class SimpleANN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim):\n",
        "        super(SimpleANN, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_layers[0]))\n",
        "        layers.append(nn.ReLU())\n",
        "        for i in range(len(hidden_layers) - 1):\n",
        "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n",
        "            layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(hidden_layers[-1], output_dim))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "hidden_layers = [16, 16]\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "\n",
        "model = SimpleANN(input_dim=X_resampled.shape[1], hidden_layers=hidden_layers, output_dim=1)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "ll7md_LTXbwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cfb133-83cd-42da-d7ef-b0b05eb9e561",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.0001\n",
            "Epoch [2/50], Loss: 0.0000\n",
            "Epoch [3/50], Loss: 0.0469\n",
            "Epoch [4/50], Loss: 0.0132\n",
            "Epoch [5/50], Loss: 0.0034\n",
            "Epoch [6/50], Loss: 0.0020\n",
            "Epoch [7/50], Loss: 0.0027\n",
            "Epoch [8/50], Loss: 0.0088\n",
            "Epoch [9/50], Loss: 0.0018\n",
            "Epoch [10/50], Loss: 0.0007\n",
            "Epoch [11/50], Loss: 0.0053\n",
            "Epoch [12/50], Loss: 0.0011\n",
            "Epoch [13/50], Loss: 0.0031\n",
            "Epoch [14/50], Loss: 0.0689\n",
            "Epoch [15/50], Loss: 0.0052\n",
            "Epoch [16/50], Loss: 0.1981\n",
            "Epoch [17/50], Loss: 0.0007\n",
            "Epoch [18/50], Loss: 0.0000\n",
            "Epoch [19/50], Loss: 0.0000\n",
            "Epoch [20/50], Loss: 0.0000\n",
            "Epoch [21/50], Loss: 0.0000\n",
            "Epoch [22/50], Loss: 0.0523\n",
            "Epoch [23/50], Loss: 0.0008\n",
            "Epoch [24/50], Loss: 0.0000\n",
            "Epoch [25/50], Loss: 0.0000\n",
            "Epoch [26/50], Loss: 0.0000\n",
            "Epoch [27/50], Loss: 0.0000\n",
            "Epoch [28/50], Loss: 0.0033\n",
            "Epoch [29/50], Loss: 0.0000\n",
            "Epoch [30/50], Loss: 0.0000\n",
            "Epoch [31/50], Loss: 0.0014\n",
            "Epoch [32/50], Loss: 0.0044\n",
            "Epoch [33/50], Loss: 0.0320\n",
            "Epoch [34/50], Loss: 0.3708\n",
            "Epoch [35/50], Loss: 0.0121\n",
            "Epoch [36/50], Loss: 0.0228\n",
            "Epoch [37/50], Loss: 0.0000\n",
            "Epoch [38/50], Loss: 0.0010\n",
            "Epoch [39/50], Loss: 0.0000\n",
            "Epoch [40/50], Loss: 0.6086\n",
            "Epoch [41/50], Loss: 0.0000\n",
            "Epoch [42/50], Loss: 0.0000\n",
            "Epoch [43/50], Loss: 0.0687\n",
            "Epoch [44/50], Loss: 0.3297\n",
            "Epoch [45/50], Loss: 0.1635\n",
            "Epoch [46/50], Loss: 0.0066\n",
            "Epoch [47/50], Loss: 0.0065\n",
            "Epoch [48/50], Loss: 0.0105\n",
            "Epoch [49/50], Loss: 0.0118\n",
            "Epoch [50/50], Loss: 0.0119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "train_dataset = TensorDataset(torch.tensor(X_resampled, dtype=torch.float32), torch.tensor(y_resampled, dtype=torch.float32).view(-1, 1))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).view(-1, 1))\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the ANN model\n",
        "class SimpleANN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim):\n",
        "        super(SimpleANN, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_layers[0]))\n",
        "        layers.append(nn.ReLU())\n",
        "        for i in range(len(hidden_layers) - 1):\n",
        "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i + 1]))\n",
        "            layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(hidden_layers[-1], output_dim))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "hidden_layers = [16, 16]\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "\n",
        "model = SimpleANN(input_dim=X_resampled.shape[1], hidden_layers=hidden_layers, output_dim=1)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "JcxmNMZQYzSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "46a6005e-d52b-4ec4-94a6-a66585921b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6364\n",
            "Epoch [2/10], Loss: 0.5199\n",
            "Epoch [3/10], Loss: 0.3391\n",
            "Epoch [4/10], Loss: 0.3079\n",
            "Epoch [5/10], Loss: 0.1692\n",
            "Epoch [6/10], Loss: 2.6235\n",
            "Epoch [7/10], Loss: 0.0633\n",
            "Epoch [8/10], Loss: 0.0513\n",
            "Epoch [9/10], Loss: 0.0132\n",
            "Epoch [10/10], Loss: 0.3137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predicted.numpy())\n",
        "\n",
        "y_true = np.array(y_true).flatten()\n",
        "y_pred = np.array(y_pred).flatten()\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX-2vxYhyLgH",
        "outputId": "2b397ec6-3945-4196-e581-9c1f5d274d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9652\n",
            "F1 Score: 0.8292\n",
            "Recall: 0.9228\n",
            "Precision: 0.7529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Accuracy: 0.9652\n",
        "# F1 Score: 0.8292\n",
        "# Recall: 0.9228\n",
        "# Precision: 0.7529\n",
        "# # Save the model to a local file\n",
        "# model_path = \"simple_model.pth\"\n",
        "# torch.save(model.state_dict(), model_path)\n",
        "# print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRH_wE6_upf8",
        "outputId": "f64b19ac-1e1f-43f1-99c6-10b39a1fd7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to simple_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "lrOArQ7Eux_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_rK4M223Lo-",
        "outputId": "f14a8100-4da1-44b1-8868-16a7119078c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [1],\n",
              "        [0],\n",
              "        [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXxjcWDe3Hmi",
        "outputId": "bf468dd2-11ec-4530-fb4d-1e94b69bebaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9916, -2.0356,  2.1439,  ...,  1.1195, -1.2136, -0.9122],\n",
              "        [ 1.0497, -0.4913, -0.5571,  ..., -0.4391,  0.1941, -0.0761],\n",
              "        [-0.5486,  0.3839,  0.0905,  ...,  3.7518, -1.8309, -1.0012],\n",
              "        ...,\n",
              "        [-2.6333, -2.5016,  3.8377,  ...,  1.6927, -1.2896, -0.9367],\n",
              "        [ 0.4434, -0.4269, -0.3947,  ..., -0.6795,  1.0965,  0.8745],\n",
              "        [-3.0334, -1.2436,  3.4932,  ...,  1.6391, -1.4486, -0.9604]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model_load(X_tensor)"
      ],
      "metadata": {
        "id": "baUNfej73I7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.round()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtOhpBLo3R4x",
        "outputId": "78eaf2b2-d07b-402d-dbb9-9e7c54d17b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [0.],\n",
              "        [1.],\n",
              "        ...,\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [1.]], grad_fn=<RoundBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the path in Google Drive\n",
        "model_path = '/content/drive/My Drive/simple_model.pth'\n",
        "\n",
        "# Load the entire model\n",
        "model1 = torch.load(model_path)\n",
        "#model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVpgxhEj3Sn-",
        "outputId": "da34266a-e37e-4070-8999-e0b0f62d6aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a local file\n",
        "model_path = \"Entire_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Entire model saved to {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I5uxZL64C4Y",
        "outputId": "fff1dd76-8b22-4e5f-d4ea-97b79e254b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entire model saved to Entire_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path in Google Drive\n",
        "drive_model_path = '/content/drive/My Drive/Entire_model.pth'\n",
        "\n",
        "# Move the local file to Google Drive\n",
        "!cp simple_model.pth \"$drive_model_path\"\n",
        "print(f\"Model uploaded to {drive_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_JXGJuA46cR",
        "outputId": "f34a21e5-df21-4d83-f237-bdd9a8fdf121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model uploaded to /content/drive/My Drive/Entire_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the path in Google Drive\n",
        "model_path = '/content/drive/My Drive/Entire_model.pth'\n",
        "\n",
        "# Load the entire model\n",
        "#state_dict = torch.load(model_path)\n",
        "#model = SimpleANN(input_dim=X_resampled.shape[1], hidden_layers=hidden_layers, output_dim=1)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully from the saved model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjVWOpln5y9l",
        "outputId": "cbca24a7-1ffd-45b8-c886-ebf3a1897506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from the saved model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQJlegWTDSwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}